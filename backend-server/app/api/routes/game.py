import asyncio
import base64
import datetime
from http.client import HTTPException
import io
import json
import logging
import uuid
from typing import Any, Dict, List, Tuple, Annotated, Union
from datetime import timedelta

from fastapi import (
    APIRouter,
    Depends,
    File,
    UploadFile,
    status,
    HTTPException,
    Body
)
from pydantic import BaseModel, Field
from sqlmodel import Session, select

from app.config.setting import settings
from app.middleware.auth import require_user, require_admin
from app.models.job import Job, JobStatus, JobType
from app.models.rabbit_message import SimulationMessageType
from app.models.user import User
from app.models.submission import Submission
from app.service.db.postgres import engine
from app.service.docker.main import DockerService
from app.service.rabbitmq.producer import MQProducer
from app.models.game import GameLog

from app.utils.file import check_input_stat, create_tar_from_files

logger = logging.getLogger(__name__)

# ──────────────────────────────────────────────────────────────────────────────
# Schemas used in Swagger / OpenAPI
# ──────────────────────────────────────────────────────────────────────────────


class MessageResponse(BaseModel):
    """Generic single‑field message response."""
    message: str = Field(..., example="Message sent to echo worker")


class SimulationQueuedResponse(BaseModel):
    """Returned when a simulation request is accepted and queued."""
    job_id: str = Field(..., example="9a11ee55-4deb-4889-baa1-1a3cee051a2c")
    job_status: str = Field("Pending", example="Pending")
    status_code: int = Field(status.HTTP_200_OK, example=200)
    message: str = Field(
        ...,
        example="Files uploaded and simulation started",
    )


class VerifySuccessResponse(BaseModel):
    message: str = Field(
        ...,
        example="Files uploaded successfully and not malformed",
    )
    status_code: int = Field(status.HTTP_200_OK, example=200)


class ErrorResponse(BaseModel):
    """Standard error wrapper used by every endpoint."""
    error: str
    status_code: int = Field(status.HTTP_400_BAD_REQUEST, example=400)


class JobStatusResponse(BaseModel):
    """Returned when a simulation job status is requested."""
    job_id: str = Field(..., example="9a11ee55-4deb-4889-baa1-1a3cee051a2c")
    job_status: str = Field("Pending", example="Pending")
    status_code: int = Field(status.HTTP_200_OK, example=200)
    message: str = Field(
        ...,
        example="Job status retrieved successfully",
    )
    error: str | None = Field(None, example=None)
    result_data: Dict[str, int] | None = Field(None, example=None)

class GameLogCreate(BaseModel):
    """Schema for receiving a new game log."""
    gameId: str
    rounds: dict
    playerNames: dict
    playerHands: dict
    finalBoard: list
    blinds: dict
    sidePots: list

class GameLogResponse(BaseModel):
    """Schema for returning a game log."""
    message: str
    game_log: GameLogCreate

# ──────────────────────────────────────────────────────────────────────────────
# Router
# ──────────────────────────────────────────────────────────────────────────────


router = APIRouter(prefix="/sim", tags=["Simulation"])

PythonFile = Annotated[
    UploadFile,
    File(
        ...,
        description='Your bot implementation **must** be named `"player.py"`.',
        media_type="text/x-python",
    ),
]

ReqsFile = Annotated[
    UploadFile,
    File(
        ...,
        description='Package list **must** be named `"requirements.txt"`.',
        media_type="text/plain",
    ),
]


# ───── Endpoints ──────────────────────────────────────────────────────────────
@router.get(
    "/log/{game_uuid}",
    summary="Retrieve a specific game log by its UUID",
    response_model=GameLogResponse,
    status_code=status.HTTP_200_OK,
    responses={404: {"model": ErrorResponse}},
)
def get_game_log(game_uuid: str):
    """
    Fetches a complete game log from the database using the
    gameId that was generated by the poker engine.
    """
    with Session(engine) as session:
        game_log_record = session.exec(select(GameLog).where(GameLog.game_uuid == game_uuid)).first()

        if not game_log_record:
            return ErrorResponse(
                error=f"Game log with gameId '{game_uuid}' not found.",
                status_code=status.HTTP_404_NOT_FOUND,
            )
        
        return GameLogResponse(
            message="Game log retrieved successfully.",
            game_log=game_log_record.game_data
        )

@router.post(
    "/echo",
    summary="Ping the echo worker",
    response_model=MessageResponse,
    status_code=status.HTTP_200_OK,
    responses={500: {"model": ErrorResponse}},
)
async def test_echo_worker() -> MessageResponse:
    """
    Send a *Hello, World!* message to the RabbitMQ **echo_queue**.

    The worker simply prints the message, verifying the queue/worker plumbing.
    """

    producer = MQProducer()
    await producer.send_message("echo_queue", {"message": "Hello, World!"})
    await producer.close()
    
    return MessageResponse(message="Message sent to echo worker")


@router.get(""
    "/status/all",
    summary="Get all user simulation jobs",
    response_model=list[JobStatusResponse],
    status_code=status.HTTP_200_OK,
    responses={
        400: {"model": ErrorResponse},
        500: {"model": ErrorResponse},
    },
)
async def get_all_jobs(
    user: User = Depends(require_user),
):
    """
    Get all simulation jobs for the current user.
    """
    with Session(engine) as session:
        jobs = session.exec(
            select(Job).where(Job.username == user.username)
        ).all()

        if not jobs:
            return []

        def parse_result_data(job):
            """Parse result_data handling different formats for backward compatibility."""
            if job.status != JobStatus.FINISHED or not job.result_data:
                return None
            
            # Handle case where result_data is already a dict (shouldn't happen, but just in case)
            if isinstance(job.result_data, dict):
                return job.result_data
            
            # Handle case where result_data is a plain number (legacy data)
            if isinstance(job.result_data, (int, float)):
                return {job.username: job.result_data}
            
            # Handle string cases
            if isinstance(job.result_data, str):
                # Try to parse as JSON first
                try:
                    parsed = json.loads(job.result_data)
                    if isinstance(parsed, dict):
                        return parsed
                    # If it's a number stored as string, wrap it
                    elif isinstance(parsed, (int, float)):
                        return {job.username: parsed}
                except json.JSONDecodeError:
                    # If JSON parsing fails, try to parse as a plain number
                    try:
                        score = float(job.result_data)
                        return {job.username: score}
                    except ValueError:
                        # If all parsing fails, return None
                        return None
            
            return None

        return [
            JobStatusResponse(
                job_id=job.id,
                job_status=job.status.value,
                message="Job status retrieved successfully",
                status_code=status.HTTP_200_OK,
                error=None if job.status != JobStatus.FAILED else job.error_message,
                result_data=parse_result_data(job),
            )
            for job in jobs
        ]


@router.get(
    "/status/{job_id}",
    summary="Check the status of a simulation job",
    response_model=JobStatusResponse,
    status_code=status.HTTP_200_OK,
    responses={
        400: {"model": ErrorResponse},
        500: {"model": ErrorResponse},
    },
)
async def get_job_status(
    job_id: str,
    user: User = Depends(require_user),
):
    """
    Check the status of a simulation job.
    The job must be owned by the current user.
    """

    with Session(engine) as session:
        job = session.get(Job, job_id)
        if not job:
            return ErrorResponse(
                error="Job not found",
                status_code=status.HTTP_404_NOT_FOUND,
            )

        if job.username != user.username:
            return ErrorResponse(
                error="You do not own this job",
                status_code=status.HTTP_403_FORBIDDEN,
            )

        def parse_result_data(job):
            """Parse result_data handling different formats for backward compatibility."""
            if job.status != JobStatus.FINISHED or not job.result_data:
                return None
            
            # Handle case where result_data is already a dict (shouldn't happen, but just in case)
            if isinstance(job.result_data, dict):
                return job.result_data
            
            # Handle case where result_data is a plain number (legacy data)
            if isinstance(job.result_data, (int, float)):
                return {job.username: job.result_data}
            
            # Handle string cases
            if isinstance(job.result_data, str):
                # Try to parse as JSON first
                try:
                    parsed = json.loads(job.result_data)
                    if isinstance(parsed, dict):
                        return parsed
                    # If it's a number stored as string, wrap it
                    elif isinstance(parsed, (int, float)):
                        return {job.username: parsed}
                except json.JSONDecodeError:
                    # If JSON parsing fails, try to parse as a plain number
                    try:
                        score = float(job.result_data)
                        return {job.username: score}
                    except ValueError:
                        # If all parsing fails, return None
                        return None
            
            return None

        return JobStatusResponse(
            job_id=job.id,
            job_status=job.status.value,
            message="Job status retrieved successfully",
            status_code=status.HTTP_200_OK,
            error=None if job.status != JobStatus.FAILED else job.error_message,
            result_data=parse_result_data(job),
        )


@router.delete(
    "/job/{job_id}",
    summary="Delete a simulation job (admin only)",
    response_model=MessageResponse,
    status_code=status.HTTP_200_OK,
    responses={
        404: {"model": ErrorResponse},
        403: {"model": ErrorResponse},
        500: {"model": ErrorResponse},
    },
)
async def delete_job(
    job_id: str,
    user: User = Depends(require_admin),
):
    """
    Delete a simulation job by ID. Only admins can delete jobs.
    This will permanently remove the job from the database.
    """
    with Session(engine) as session:
        job = session.get(Job, job_id)
        if not job:
            return ErrorResponse(
                error="Job not found",
                status_code=status.HTTP_404_NOT_FOUND,
            )

        # Store job info for response message
        job_username = job.username
        job_status = job.status.value

        # If job is sim_admin, delete all related game logs
        if job.tag == JobType.SIM_ADMIN:
            logs = session.exec(select(GameLog).where(GameLog.job_id == job_id)).all()
            for log in logs:
                session.delete(log)
            logger.info(f"Deleted {len(logs)} game logs related to job {job_id}")

        # Delete the job
        session.delete(job)
        session.commit()

        logger.info(f"Admin {user.username} deleted job {job_id} (user: {job_username}, status: {job_status})")

        return MessageResponse(
            message=f"Job {job_id} deleted successfully"
        )


@router.post(
    "/async_run_user",
    summary="Queue a game with real users for a specified number of rounds.",
    response_model = Union[SimulationQueuedResponse, ErrorResponse],
    status_code=status.HTTP_200_OK,
    responses={
        400: {"model": ErrorResponse},
        404: {"model": ErrorResponse},
        500: {"model": ErrorResponse},
    },
)
async def async_run_user_simulation(
    users_list: List[str] = Body(...),
    num_rounds: int = Body(default=6),
    blind: int = Body(default=4, description="Initial blind amount (optional)"),
    blind_multiplier: float = Body(default=1.0, description="Blind multiplier (optional)"),
    blind_increase_interval: int = Body(default=1, description="Blind increase interval (optional)"),
    user: User = Depends(require_admin)
):
    """
        Queue a run between 6 users.
        Users in the list must be valid and must have final submission.
        Optionally specify blind, blind_multiplier, and blind_increase_interval for the game server.
    """

    # Check num of users in the list to be a maximum of 6
    if len(users_list) != settings.NUM_PLAYERS_PER_GAME:
        raise HTTPException(status_code=status.HTTP_400_BAD_REQUEST, detail="Must have 6 users in users_list")

    # Check whether all users is valid
    with Session(engine) as session:
        for username in users_list:
            temp_user = session.exec(select(User).where(User.username == username)).first()
            if not temp_user:
                raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"{username} not found")
            
            temp_sub = session.exec(select(Submission).where(Submission.username == username, Submission.final == True)).first()
            if not temp_sub:
                raise HTTPException(status_code=status.HTTP_404_NOT_FOUND, detail=f"Final submission for user {username} not found")

    # Create the job and add it to the DB
    job_id = str(uuid.uuid4())
    with Session(engine) as session:
        job = Job(id=job_id, username=user.username, status=JobStatus.PENDING, tag=JobType.SIM_ADMIN)
        session.add(job)
        session.commit()
        
    # send the job to the queue
    producer = MQProducer()
    message = {
        "job_id": job_id,
        "username": user.username,
        "users_list": users_list,
        "num_rounds": num_rounds,
        "type": SimulationMessageType.RUN_USER.value,
    }
    if blind is not None:
        message["blind"] = blind
    if blind_multiplier is not None:
        message["blind_multiplier"] = blind_multiplier
    if blind_increase_interval is not None:
        message["blind_increase_interval"] = blind_increase_interval
    await producer.send_message(
        "simulation_queue", message
    )
    logger.info(f"Sent message to simulation_queue: {message}")
    await producer.close()

    return SimulationQueuedResponse(job_id=job_id, message="Simulation started for specified users")





@router.post(
    "/async_run",
    summary="Submit a simulation job (asynchronous)",
    response_model=Union[SimulationQueuedResponse, ErrorResponse],
    status_code=status.HTTP_200_OK,
    responses={
        400: {"model": ErrorResponse},
        500: {"model": ErrorResponse},
    },
)
async def async_run_test_simulation(
    python_file: PythonFile,
    packages_file: ReqsFile,
    user: User = Depends(require_user),
):
    """
    Upload `player.py` + `requirements.txt` and queue a simulation run.
    Check status in `/sim/status/{job_id}`.   
    """
    # Filename checks ---------------------------------------------------------
    if python_file.filename != "player.py":
        return ErrorResponse(
            error="Python file must be named player.py",
            status_code=status.HTTP_400_BAD_REQUEST,
        )

    if packages_file.filename != "requirements.txt":
        return ErrorResponse(
            error="Packages file must be named requirements.txt",
            status_code=status.HTTP_400_BAD_REQUEST,
        )

    # Check job limit and cleanup old jobs for non-admin users ----------------
    with Session(engine) as session:
        job_count = session.exec(
            select(Job).where((Job.username == user.username) & (
                Job.status.in_([JobStatus.PENDING, JobStatus.RUNNING])))
        ).all()

        if len(job_count) >= settings.MAX_JOB_RUNNING_PER_USER:
            return ErrorResponse(
                error="You have reached the maximum number of running jobs",
                status_code=status.HTTP_400_BAD_REQUEST,
            )
        
        # Clean up old jobs for non-admin users (older than 2 weeks)
        # if not user.admin:
        # two_weeks_ago = datetime.datetime.now() - timedelta(days=2)
        # old_jobs = session.exec(
        #     select(Job).where(
        #         (Job.username == user.username) & 
        #         (Job.created_at < two_weeks_ago)
        #     )
        # ).all()
        
        # if old_jobs:
        #     for old_job in old_jobs:
        #         session.delete(old_job)
        #     session.commit()
        #     logger.info(f"Cleaned up {len(old_jobs)} old jobs for user {user.username}")
        # else:
        #     logger.info(f"No old jobs to clean up for user {user.username}")

    # Create DB job -----------------------------------------------------------
    job_id = str(uuid.uuid4())
    with Session(engine) as session:
        job = Job(id=job_id, username=user.username, status=JobStatus.PENDING)
        session.add(job)
        session.commit()

    # Package & enqueue -------------------------------------------------------
    tarstream = create_tar_from_files(
        {"player.py": python_file, "requirements.txt": packages_file}
    )

    tar_encoded = base64.b64encode(tarstream.getvalue()).decode("utf-8")
    producer = MQProducer()
    await producer.send_message(
        "simulation_queue",
        {
            "job_id": job_id,
            "python_file": python_file.filename,
            "packages_file": packages_file.filename,
            "tarstream": tar_encoded,
            "username": user.username,
            "type": SimulationMessageType.RUN.value,
        },
    )
    await producer.close()

    return SimulationQueuedResponse(job_id=job_id, message="Files uploaded and simulation started")


@router.post(
    "/verify",
    summary="Dry‑run verification of your submission",
    response_model=VerifySuccessResponse,
    status_code=status.HTTP_200_OK,
    responses={
        400: {"model": ErrorResponse},
        500: {"model": ErrorResponse},
    },
)
async def run_test_simulation(
    python_file: PythonFile,
    packages_file: ReqsFile,
    _: User = Depends(require_user),
):
    """
    Spin up a disposable container, copy your code inside and run *static
    checks*:

    1. `pip install -r requirements.txt`  
    2. Custom malformed‑file checks (`malform_file_client_check`)

    The container is always removed afterwards.  **No simulation is run.**
    """
    # Filename checks (reuse same logic as /async_run) ------------------------
    if python_file.filename != "player.py":
        return ErrorResponse(
            error="Python file must be named player.py",
            status_code=status.HTTP_400_BAD_REQUEST,
        )

    if packages_file.filename != "requirements.txt":
        return ErrorResponse(
            error="Packages file must be named requirements.txt",
            status_code=status.HTTP_400_BAD_REQUEST,
        )

    # Container bootstrapping -------------------------------------------------
    docker_service = DockerService()
    current_time = datetime.datetime.now()
    container_name = f"client_test_{current_time:%Y%m%d%H%M%S}"

    docker_service.client.containers.run(
        image=settings.RUNNER_IMAGE,
        name=container_name,
        detach=True,
        mem_limit="100m",
    )

    tarstream = create_tar_from_files(
        {"player.py": python_file, "requirements.txt": packages_file}
    )
    docker_service.client.containers.get(
        container_name).put_archive("/app", tarstream)

    ok, err = check_input_stat(docker_service, container_name)

    if not ok:
        return ErrorResponse(error=err, status_code=status.HTTP_400_BAD_REQUEST)

    docker_service.stop_and_remove_container(container_name)
    return VerifySuccessResponse(
        message="Files uploaded successfully and not malformed"
    )
